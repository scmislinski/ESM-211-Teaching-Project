---
title: "Modeling Out Data"
format: 
  html: 
    code-fold: show
    toc: true
    number-sections: true
    embed-resources: true
    message: false 
    warning: false
editor: visual
theme: lumen
execute:
  echo: true
  message: false
  warning: false
---

# library

Use the library enmpa for the tools Use terra for the mapping

```{r}
library(enmpa) #this has the functions for running the models
library(terra) #this package helps with the visulization
library(tidyverse) #keeps things clean
library(here) #makes saving and uploading data sets easier
library(geodata) #has the 
library(predicts)

```

# Cleaning the Data and Linking it to the Bioclim Data

## Getting the Bio Data

This code gets the bioclim data

```{r}
#load bioclim data. This data is used for fitting the model and making a pretty graph
bioclim_data <- worldclim_global(var = "bio",
                                    res = 2.5,
                                    path = "Data/") 
```
This is all the different environmental data stored in this package:
Temperature Variables:

BIO1 – Annual Mean Temperature
BIO2 – Mean Diurnal Range (Mean of monthly (max temp - min temp))
BIO3 – Isothermality (BIO2/BIO7) (* 100)
BIO4 – Temperature Seasonality (standard deviation * 100)
BIO5 – Max Temperature of Warmest Month
BIO6 – Min Temperature of Coldest Month
BIO7 – Temperature Annual Range (BIO5-BIO6)
BIO8 – Mean Temperature of Wettest Quarter
BIO9 – Mean Temperature of Driest Quarter
BIO10 – Mean Temperature of Warmest Quarter
BIO11 – Mean Temperature of Coldest Quarter

Precipitation Variables:
BIO12 – Annual Precipitation
BIO13 – Precipitation of Wettest Month
BIO14 – Precipitation of Driest Month
BIO15 – Precipitation Seasonality (Coefficient of Variation)
BIO16 – Precipitation of Wettest Quarter
BIO17 – Precipitation of Driest Quarter
BIO18 – Precipitation of Warmest Quarter
BIO19 – Precipitation of Coldest Quarter

For this, we're using BIO 1 and BIO 2, Annual Mean Temperature and Annual Precipitation.

## Loading Our Data

```{r}
#This is the milkweed data. Need to clean it, and change the names to make it easier to use in later steps
obs_data_mw <- read_csv(here("Data","Milkweed.csv")) |>
  select(gbifID, decimalLatitude, decimalLongitude) |> drop_na()|>
  rename(latitude=decimalLatitude) |> 
  rename(longitude=decimalLongitude)
```

## Cleaning Bioclim data and Linking it to the Milkweed Data Set

```{r}
# This bit of code allows us to crop the bioclim data for just the section we have for the milkweed.
max_lat <- ceiling(max(obs_data_mw$latitude))
min_lat <- floor(min(obs_data_mw$latitude))
max_lon <- ceiling(max(obs_data_mw$longitude))
min_lon <- floor(min(obs_data_mw$longitude))

# Store boundaries in a single extent object
geographic_extent <- ext(x = c(min_lon, max_lon, min_lat, max_lat))

# This makes a pretty map for our milkweed data.
world_map <- world(resolution = 3,
                   path = "data/")
# Crop the map to our area of interest
my_map <- crop(x = world_map, y = geographic_extent)
# Plot the base map
plot(my_map,
     axes = TRUE,
     col = "grey95")
# Add the points for individual observations
points(x = obs_data_mw$longitude,
       y = obs_data_mw$latitude,
       col = "darkgreen",
       pch = 20,
       cex = 0.75)
```

# Preparing the Data for Modeling

```{r}
#prepare the data for modeling

sample_extent <- geographic_extent * 1.25
# Crop bioclim data to desired extent
bioclim_data <- crop(x = bioclim_data, y = sample_extent)

# Plot the first of the bioclim variables to check on cropping
plot(bioclim_data[[1]]) #this a good way to make sure the boundries are good!
```

## Pseudo-absences

This is how we get pseudo absences out of the milkweed data.

```{r}
set.seed(1234) #This insures we get the same results every time. You can always change it to your favorite number

# Randomly sample points (same number as our observed points)
background_mw <- spatSample(x = bioclim_data,
                         size = 500, # generate 500 pseudo-absence points
                         values = FALSE, # don't need values
                         na.rm = TRUE, # don't sample from ocean
                         xy = TRUE) # just need coordinates

# Pull out coordinate columns, x (longitude) first, then y (latitude) from
# saguaro data
presence_mw  <- obs_data_mw[, c("longitude", "latitude")]

# Add column indicating presence
presence_mw$pa <- 1

# Convert background data to a data frame
absence_mw <- as.data.frame(background_mw)
# Update column names so they match presence points
colnames(absence_mw) <- c("longitude", "latitude")
# Add column indicating absence
absence_mw$pa <- 0
# Join data into single data frame
all_points_mw <- rbind(presence_mw, absence_mw)


#add the climate data to the milk weed data
bioclim_extract_mw <- terra::extract(x = bioclim_data,
                           y = all_points_mw[, c("longitude", "latitude")],
                           ID = FALSE) # No need for an ID column 
#### for what ever reason, you need to specify that the extract function is coming from the terra package so the "terra::" portion is absolutely critical

# Add the point and climate datasets together
points_climate_mw <- cbind(all_points_mw, bioclim_extract_mw) 

#select the columns that you need. 
points_climate_mw <- points_climate_mw |> select(longitude, latitude, pa, wc2.1_2.5m_bio_1, wc2.1_2.5m_bio_12)

```


# Model Formulations
This is how you set up which models to test. Here, you can change the environmental variables, but for now we're sticking to Annual Mean Temperature and Annual Precipitation.
```{r}
get_formulas(dependent = "Sp", independent = c("wc2.1_2.5_bio_1", "wc2.1_2.5_bio_12"),  
             type = "lq", mode = "moderate")
```

# Running the enmpa Package
The function calibration_glm() is a general function that allows to perform the following steps:

Partition data in k-folds
Create formulas for candidate models
Fit and evaluate candidate models
Select best performing models
Model selection consists of three steps:

A first filter to keep the models with ROC AUC >= 0.5 (statistically significant models).
A second filter to maintain only models that meet a selection_criterion (“TSS”: TSS >= 0.4; or “ESS”: maximum Accuracy - tolerance).
From those, pick the ones with delta AIC <= 2.

The results are returned as a list containing:

Selected models (*$selected)
A summary of statistics for all models (*$summary)
Results obtained from cross-validation for all models (*$calibration_results)
Input data used (*$data)
The weights used (*$weights)
The list of partition indices (*$kfold_index_partition)
```{r}
points_climate_mw <- as.data.frame(points_climate_mw, xy = TRUE)

calibration <- calibration_glm(data = points_climate_mw, dependent = "pa",
                               independent = c("wc2.1_2.5m_bio_1", "wc2.1_2.5m_bio_12"),
                               response_type = "lpq",
                               formula_mode = "moderate", 
                               exclude_bimodal = TRUE, 
                               selection_criterion = "TSS",
                               cv_kfolds = 5, 
                               verbose = FALSE)
calibration
#> enmpa-class `enmpa_calibration`:
#> $selected             : Selected models (N = 2)
#> $summary              : A summary of statistics for all models. 
#> $calibration_results  : Results obtained from cross-validation for all models. 
#> $data                 : Data used for calibration. 
#> $partitioned_data     : k-fold indexes (k = 5)
#> $weights              : Use of weights (FALSE)
 
summary(calibration)
```
Model number 7 was the only one fit well.

## Fitting the Model
After one or more models are selected, the next steps are the fitting and projection of these models. In this case we are projecting the models to the whole area of interest. Models can be transferred with three options: 
Free Extrapolation (‘E’) 
Extrapolation with clamping (‘EC’) 
No Extrapolation (‘NE’).
```{r}

#env_vars <- rast(system.file("extdata", "vars.tif", package = "enmpa")) 
  
fits <- fit_selected(calibration) 

 #Prediction for the two selected models and their consensus
preds_E  <- predict_selected(fits, newdata = bioclim_data, extrapolation_type = "E",
                             consensus = TRUE)
preds_NE <- predict_selected(fits, newdata = bioclim_data,extrapolation_type = "NE",
                             consensus = TRUE)

# Visualization of the Models
plot(c(preds_E$predictions, preds_NE$predictions),
     main = c("Model ID 7 (Free Extrapolation)",
              "Model ID 7 (No Extrapolation)"),
     mar = c(1, 1, 2, 5))
```

## Response Curve
An important step in understanding the ecological niches with these models is to explore variable response curves. The following lines of code help to do so:
```{r}
response_curve(fitted = fits, modelID = "ModelID_7", variable = "wc2.1_2.5m_bio_1")
response_curve(fitted = fits, modelID = "ModelID_7", variable = "wc2.1_2.5m_bio_12")
```

# Homework Assignment

Run the demo but with the monarch data set.

## Load, Clean, and Create Psudo Absence Data
**Plot the monarch data. What are the differences and similarities between the monarch map and the milkweed map that we made in the demo?**


```{r}

```

## Use the calibration_glm() Function to Identify Best Model

**What is the best model?**

```{r}

```

## Fit and Create Projections for the Selected Model

**What is the model saying for monarchs?**

```{r}

```

## Create a Response Curve for the Two Environmental Parameters

**What are the response curves saying about the two environmental parameters?**

```{r}

```

## Compare the Model Progections and Response Curves of the Milkweed and Monarch Data Sets

**Where would you expect monarchs to be seen due to the presence of milkweed but there were no observations of monarchs? What is a probable explanation for that?**

**Where would you expect milkweed to be seen due to the presence of monarchs but there were no observations of milkweed? What is a probable explanation for that?**

**Are there any other surprises in the models or the data?**
